## Module Impression
In this module I get to find out about different kinds of tools and Artificial Intelligence applications. Starting this module I was unsure whether I'd be able to keep up because of my basic knowledge in coding in general. Nonetheless I was looking forward to discover a completely unknown area in machine learning and for example image generation which was one of the first topic we were studying in our online class. The setting being an online class in Zoom and the language being English was unusual but it worked out and I found out that I need to polish my language skills again. Getting familiar with using a GPU Hub was a task but eventually I got there realizing products also outside the lessons. Using [Stable Diffusion WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki) and [Fooocus](https://github.com/lllyasviel/Fooocus) is very interesting and experimenting with prompts and external models from [Civitai](https://civitai.com/) was not something I expected to spend dozens of hours into just for fun. Normally I'm not really into documentaries but the ones our module professor Guillaume recommended I was able to follow thoroughly and realized what a massive area of research all this Artificial Intelligence topic is. The next Machine Learning principle we took a look in class was the concept of Large Language Models. Confused at the beginning we tackled on some models like [gpt4all](https://gpt4all.io/index.html) to have it give responses to some input prompts. Having a chatbot like model inside a notebook that you set up and execute has something magical to it. Before I knew it we were fast approaching the middle of the semester and each student came up with a project idea to take off for the remainder of the module with grateful support from the professor and fellow students. My first ideas were 1. a music generator for calming and atmospheric sounds and 2. a chatbot which recommends the user a character to play with in the game Super Smash Bros Ultimate by having game-specific questions answered. Something that caught my eyes before starting this module was that in the prior class there was a group that made a music generator for [LoFi Hiphop](https://necri.github.io/). And that fascination accompanied me until the project kick off. Therefore I was looking forward to seeing the input to audio generation. We played around with various tools like [Bark](https://github.com/suno-ai/bark?tab=readme-ov-file) or [XTTS](https://huggingface.co/spaces/coqui/xtts) and I was certain to try out my first idea for the module project. I might have played around too much since I only had experiments rather than showable progress during lessons but I really appreciated the support options from Guillaume and fellow students. At the day of the presentation I was amazed by all the projects and to see what kind of various ways there were to use AI tools. 
Structure: I was easily overwhelmed with the content but the class is structured to let students decide for themselves how deep they want to dive into a topic. The course was well-structured with openness to discuss about something more if the demand is there. 
Environment: Despite it being an online class it was well managed with providing information and ressources. We were instructed to prepare a VPN to get full access to the GPU Hub so we can follow well with the lectures. It also allows recording a session so we can take a look into it afterwards again to refresh a step.
Learning behaviour: Personally the introductions to a new topic were sometimes a bit demanding but the immediate practice definitely helped. The speed of the lectures were fine. I was able to comprehend the steps when working in the GPU Hub. The time used outside of class were appropriate. 

## Project
Create a mindfulness assistance helping the user to calm down with breathing instructions and ai generated background music

### Idea 
In my observations employed people are very ambitious to get things done and tend to neglect taking breaks. You can see commuters in the train station walking in a straight line with only one objective in their vision. But no matter how stressful one's day is there is always a short amount of time where you distance yourself from a task and it's when we go to the bathroom. Public toilets often have that peculiarly calming sounds in the background which allows the brain to hit the brakes and bring the body and mind to the state of piece. After leaving the room you can tackle the work with some kind of mind-reset.

### Process
Due to having recently finished a module for the introduction to web development I wanted to make a webpage that plays generated music pieces. Quickly after making an [After Effects Sketch](https://drive.google.com/file/d/1mCf8AV8VjCWVD2Oo5Jj5EaYekVxPo3t1/view?usp=sharing) I tried to create a visually pleasing site with the purpose of having a calming effect to the user. Thanks to a mindless scrolling thorugh X I came across the ai music generator SunoAI. With this one I immediately generated the result I had in mind and created a bunch of sounds to later use for the breathing assistant. Having an animation running while playing calming music was rather easily manageable. The animations shows a sphere in the middle of the screen growing and shrinking indicating the timing of inhaling and exhaling. Having a scene like that is pretty much what I expected but what if there was an actual practitioner telling you to get comfortable and blend out the surrounding? I set up the XTTS with in the GPU Hub and had the teacher's voice that I had previously cloned before just for fun say the instructions before the breathing session. I made a start menu with fluid transitions to choose between a guided practice and a free breathing sitting. 

### What's next
The site is provided with pre-generated sounds. To have it to be called a music generator it has to make music on the go. For that I need to take a look into the implementation of APIs for a music gen model in p5.js.

